---
title: "9 - Metropolis Hastings Proof"
date: 2019-05-24
categories: Bayesian
mathjax: true
---



In this post, we will see how Metropolis-Hasting algorithm converges to target distribution. Before we get into the proof, we need to know some of the notions.

- **Irreducible**: One can get to any other state z from any state x with probability greater than zero
- **Aperiodic**: One can return to any state x at anytime
- **Ergodic**: One have both irreducible and aperiodic properties
- **Reversible**: It is called reversible if there exists a distribution $$P(x)$$ such that $$P(x^*)J(x \mid x^*) = P(x)J(x^* \mid x)$$

 A Markov chain is guaranteed that stationary distribution can be reached from any given initial distribution, if the chain is ergodic. In other words, it eventually converges.

In order to prove Metropolis-Hastings converges to the target distribution, there are two steps. First, we have to show the Markov chain gets to a unique stationary distribution. Next, we need to prove the stationary distribution equals to the target distribution.

For the first part, the Markov chain has a unique stationary distribution if it is irreducible, aperiodic and not transient(recurrent). The latter two conditions hold for a random walk on any proper distribution, and irreducibility holds as long as we choose to use a distribution with positive probability of reaching from any state to any other state.

Now we have to show the target distribution is the stationary distribution of the Markov chain generated by Metropolis-Hastings.

Recall some of notations:

$$ \theta =$$ state

$$ J_t(\cdot \mid \cdot) = $$ Jumping or proposal distribution from one state to other





## Reference

- STAT 578: Advanced Bayesian Modeling by Professor Trevor Park
- Gelman, A., Stern, H. S., Carlin, J. B., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.



