---
title: "5 - NIPALS"
date: 2019-05-24
categories: Machine
mathjax: true
---

Last time, we talked about Principle Component Analysis. PCA requires to evaluate covariance matrix of data. And the problem is when the data gets big or have high dimension, it is difficult to estimate the covariance matrix. So alternative way of getting principle components are Nonlinear Iterative Partial Least Squares(NIPALS) or Singular Value Decomposition(SVD). In this post, we will talk about NIPALS.

For simplicity, we define data $$X$$ has zero mean.

$$ X = \left(\begin{array}) x_1^T  \\ x_2^T \\ ... \\ x_N^T \end{array}\right)$$

where each row vector represents each data vector. Now, suppose we want to find the first principal component, $$u$$. That is, we approximate $$x_i$$ by taking $$w_i u $$. We can stack $$[w_1, w_2, ..., w_N] = W$$. And the matrix $$Wu^T$$ is a good approximation of data $$X$$.

We use **Frobenius norm** is a matrix norm obtained by summing squared entries of the matrix. By using Frobenius norm, we can define cost

$$ C(w, u ) = \| X - wu^T \|_F^2 $$

$$  = \sum_{ij} (x_{ij} - w_i u_j)^2 $$

We need to find proper pairs of $$w$$ and $$u$$. However, there is no unique choice, since the pair $$(sw, \frac{1}{s}w)$$, and the pair $$(w, u)$$ gives same cost. So, we will set $$u$$ as an unit vector, where $$ \|u\| = 1 $$.



Taking partial derivatives of the cost function gives us solutions of parameters.

$$ \frac{\partial C} {\partial w_k} = \sum_j (x_{jk} - w_k u_j) u_j $$

$$ \nabla_w C = (X - wu^T)u  $$

For $$u$$,

$$ \frac{\partial C} { \partial u_l} = \sum_k (x_il - w_i u_l) w_i $$

$$ \nabla_u C = (X^T - uw^T)w $$



Setting these partial derivatives zero, we can update $$w$$ and $$u$$ iteratively:

$$\hat w = \frac{Xu^{(n)})} {(u^{(n)})^T u^{(n)} } $$

$$ \hat u = \frac {X^T \hat w}{\hat w^T \hat w} $$

By rescaling, we can ensure $$u$$ is unit vector. Let $$ s = \sqrt{(\hat u)^T \hat u} $$, then

$$ u^{(n+1)} = \frac {\hat u}{s}$$

$$ w^{(n+1)} = s \hat w $$



We can check for convergence by checking whether below value is small

$$ \mid u^{(n+1)} - u^{(n)} \mid $$



Note that NIPALS is helpful for finding first few principal components. However, if many components are computed, numerical errors will overwhelm, giving incorrect results.



## Reference

- CS498 Applied Machine Learning by Professor Trevor Walker
- Bishop, C. M. (2006). *Pattern recognition and machine learning*. springer.
